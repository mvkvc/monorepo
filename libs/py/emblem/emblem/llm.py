# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/04_llm.ipynb.

# %% auto 0
__all__ = ['completion', 'generate_question_prompt', 'generate_question']

# %% ../nbs/04_llm.ipynb 3
from abc import ABC
from typing import Literal
import openai

from .core import env_or_raise
from .data import clean
from .data import Chunks

# %% ../nbs/04_llm.ipynb 4
def completion(text: str, model: Literal["gpt-3.5-turbo", "gpt-4"] = "gpt-4") -> str:
    if model in ["gpt-3.5-turbo", "gpt-4"]:
        if not hasattr(openai, "key"):
            key = env_or_raise("OPENAI_API_KEY")
            openai.key = key

        # TODO: Add error handling, rate limits etc.
        completion = openai.ChatCompletion.create(
            model=model, messages=[{"role": "user", "content": text}]
        )
        response = completion.choices[0].message.content
    else:
        raise ValueError("Invalid model selected.")

    return response

# %% ../nbs/04_llm.ipynb 6
def generate_question_prompt(text: str, n: int = 1, template=None, **kwargs) -> str:
    if template is None:
        template = """
        You are a tenured professor preparing questions to ask about the text provided.
        Given the following text snippet, try to create a unique knowledge question that 
        tests understanding of the source material. Response only with your question and 
        nothing else.

        SOURCE:
        {text}
        """

    replacements = {"text": text, **kwargs}
    for key, value in replacements.items():
        template = template.replace("{" + key + "}", str(value))

    return clean(str.encode(template))

# %% ../nbs/04_llm.ipynb 8
def generate_question(
    text: str,
    template=None,
    model: Literal["gpt-3.5-turbo", "gpt-4"] = "gpt-4",
    **kwargs
):
    prompt = generate_question_prompt(text, template, **kwargs)
    response = completion(prompt, model)

    return response

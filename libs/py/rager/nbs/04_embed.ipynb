{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# embed\n",
    "\n",
    "> Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from functools import partial\n",
    "from typing import Awaitable, Callable, List, Union\n",
    "\n",
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "MAX_BATCH_OPENAI = 2048\n",
    "MAX_BATCH_SENTENCE_TRANSFORMER = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "EmbedClient = Union[AsyncOpenAI, SentenceTransformer]\n",
    "EmbedResult = List[Union[float, np.array]]\n",
    "EmbedFn = Callable[[str], Union[Awaitable[EmbedResult], EmbedResult]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class EmbedModel(BaseModel):\n",
    "    async_: bool\n",
    "    init_key: Union[str, None]\n",
    "    max_input_size: int\n",
    "    fn_init: Callable[[Union[str, None]], EmbedClient]\n",
    "    fn_embed: Callable[[EmbedClient], EmbedFn]\n",
    "    max_batch: int = Field(default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "class EmbedRequest(BaseModel):\n",
    "    text: Union[str, List[str]]\n",
    "    model_str: str = Field(default=\"openai_text_embedding_3_small\")\n",
    "    output_size: Union[int, None] = Field(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def init_openai() -> AsyncOpenAI:\n",
    "    return AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def init_sentence_transformer(model: str) -> SentenceTransformer:\n",
    "    return SentenceTransformer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def embed_openai(client: AsyncOpenAI, model: str) -> EmbedFn:\n",
    "    async def _embed_openai(text: str) -> EmbedResult:\n",
    "        response = await client.embeddings.create(input=[text], model=model)\n",
    "        return response.data[0].embedding\n",
    "\n",
    "    return _embed_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "def embed_sentence_transformer(client: SentenceTransformer) -> EmbedFn:\n",
    "    return lambda text: client.encode([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "\n",
    "\n",
    "embed_supported = {\n",
    "    \"openai_text_embedding_3_small\": EmbedModel(\n",
    "        init_key=\"openai\",\n",
    "        max_input_size=8191,\n",
    "        fn_init=partial(AsyncOpenAI),\n",
    "        fn_embed=partial(embed_openai, model=\"text-embedding-3-small\"),\n",
    "        async_=True,\n",
    "        max_batch=MAX_BATCH_OPENAI,\n",
    "    ),\n",
    "    \"openai_text_embedding_3_large\": EmbedModel(\n",
    "        init_key=\"openai\",\n",
    "        max_input_size=8191,\n",
    "        fn_init=partial(AsyncOpenAI),\n",
    "        fn_embed=partial(embed_openai, model=\"text-embedding-3-large\"),\n",
    "        async_=True,\n",
    "        max_batch=MAX_BATCH_OPENAI,\n",
    "    ),\n",
    "    \"jina-embeddings-v2-base-en\": EmbedModel(\n",
    "        init_key=\"jina-embeddings-v2-base-en\",\n",
    "        max_input_size=8191,\n",
    "        fn_init=partial(SentenceTransformer, \"jinaai/jina-embeddings-v2-base-en\"),\n",
    "        fn_embed=partial(embed_sentence_transformer),\n",
    "        async_=False,\n",
    "        max_batch=MAX_BATCH_SENTENCE_TRANSFORMER,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
